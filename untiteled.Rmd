```{r}
parrse <- function(path) {
  data_from_file <- read.csv(path)
  data <- data_from_file[, (3:4)]
  
  
  stop_words <- read_file("stop_words.txt")
  splitted_stop_words <- strsplit(stop_words, split='\n')
  splitted_stop_words <- splitted_stop_words[[1]]
  
  
  tidy_text <- unnest_tokens(data, 'splitted', 'text', token="words") %>%
               filter(!splitted %in% splitted_stop_words)
  # tidy_text = author : word
  
  term_frequency <- tidy_text %>% count(splitted,sort=TRUE)
  #amount of each word
  
  number_of_all <- sum(term_frequency$n)
  
  
  lovecraft_words <- tidy_text[tidy_text$author == "HP Lovecraft",]
  amount_lovecraft_words <- lovecraft_words %>% count(splitted,sort=TRUE)
  
  
  poe_words <- tidy_text[tidy_text$author == "Edgar Alan Poe",]
  amount_poe_words <- poe_words %>% count(splitted,sort=TRUE)
  
  
  mary_words <- tidy_text['M' %in% tidy_text$author,]
  amount_mary_words <- mary_words %>% count(splitted,sort=TRUE)
  
  output <- list(number_of_all, term_frequency, amount_lovecraft_words, amount_poe_words, amount_mary_words)
}

```

```{r}
lst <- parrse("data/0-authors/train.csv")
lst
```

